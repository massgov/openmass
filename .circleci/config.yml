version: 2.1
orbs:
  jira: circleci/jira@1.3.1
  node: circleci/node@4.9.0

# YAML anchors/aliases. See;
# - https://circleci.com/blog/circleci-hacks-reuse-yaml-in-your-circleci-config-with-yaml/
# - https://github.com/circleci/frontend/blob/master/.circleci/config.yml
references:
  # Dynamic hosts mean constantly checking interactively that we mean to connect to an unknown host. We ignore those here.
  no_host_check: &no_host_check
    run: {name: 'Disable StrictHostKeyChecking', command: 'mkdir -p $HOME/.ssh && echo "StrictHostKeyChecking no" > ~/.ssh/config'}

  no_ssh_timeout: &no_ssh_timeout
    run: {name: 'Disable SSH timeout', command: 'echo "ServerAliveInterval 30" >> ~/.ssh/config'}

  vendor_bin_add_path: &vendor_bin_add_path
    run: echo 'export PATH=vendor/bin:node_modules/.bin:$PATH' >> $BASH_ENV

  restore_composer_cache: &restore_composer_cache
    restore_cache:
      name: Restore Composer Cache
      keys:
        - site-composer-v16-{{ checksum "composer.lock" }}

  save_composer_cache: &save_composer_cache
    save_cache:
      name: Save Composer cache
      key: site-composer-v16-{{ checksum "composer.lock" }}
      paths: [ vendor, docroot/core, docroot/modules/contrib, docroot/themes/contrib ]

  # Runs yarn install with caching https://circleci.com/developer/orbs/orb/circleci/node#commands-install-packages.
  yarn_install: &yarn_install
    node/install-packages:
      pkg-manager: yarn
      cache-version: v1001

  branch_ignore: &branch_ignore
    ignore:
      - /^release\/.*$/
      - /^hotfix\/.*$/
      - /^mayflower\/.*$/
      - master
      - /^mayflower-dev-.*/

executors:
  base:
    parameters:
      instance:
        type: string
        default: massgov/mysql-sanitized:latest
    working_directory: /var/www/code
    # https://circleci.com/docs/2.0/configuration-reference/#resource_class
    resource_class: xlarge
    docker:
      - image: massgov/drupal-container:1.1.0-ci
        environment:
          COMPOSER_ALLOW_SUPERUSER: 1
          DOCKER_ENV: ci
          APACHE_DOCROOT: /var/www/code/docroot
          MYSQL_USER: circle
          MYSQL_PASSWORD: circle
          MYSQL_DATABASE: circle
          MYSQL_HOST: 127.0.0.1
          MEMCACHED_HOST: 127.0.0.1
          DTT_BASE_URL: http://mass.local
          DTT_API_URL: http://mass.local:9222
          BROWSERTEST_OUTPUT_DIRECTORY: /tmp
      - image: << parameters.instance >>
        auth:
          username: $DOCKER_USER
          password: $DOCKER_API_KEY
        environment:
          MYSQL_USER: circle
          MYSQL_PASSWORD: circle
          MYSQL_DATABASE: circle
          MYSQL_RANDOM_ROOT_PASSWORD: 1
        command: --max_allowed_packet=32M --innodb_flush_method=O_DIRECT --tmp_table_size=16M --query_cache_size=16M --innodb-flush-log-at-trx-commit=2  --innodb_buffer_pool_size=500M --innodb_log_buffer_size=64M --skip-innodb_doublewrite --innodb_log_file_size=64M
      - image: memcached:1-alpine
        command: memcached -m 128
      - image: seleniarm/standalone-chromium:4.1.4-20220429

commands:
  git_configure_user:
    steps:
      - run: git config --global user.email "circleci@example.com"
      - run: git config --global user.name "CircleCI Deployment Bot"
  fetch_drush_aliases:
    parameters:
      destination:
        type: string
        default: "./drush/sites/self.site.yml"
    steps:
      - run: "curl --create-dirs -f -o << parameters.destination >> -L https://$GITHUB_MASSGOV_BOT_TOKEN@raw.githubusercontent.com/massgov/massgov-internal-docs/master/self.site.yml"
  enable_cacheability_headers:
    steps:
      - run:
          name: Enable Drupal HTTP debug cacheability headers
          command: cp -f docroot/core/assets/scaffold/files/development.services.yml docroot/sites

# See https://medium.com/labs42/monorepo-with-circleci-conditional-workflows-69e65d3f1bd0
parameters:
  webhook:
    type: boolean
    default: true

  # These params for currently used in drush ma:cf-deploy
  ma-cf-deploy:
    type: boolean
    default: false
  # These params for currently used in drush ma:backstop. target is declared later.
  reference:
    type: string
    default: ""
  tugboat:
    type: string
    default: ""
  list:
    type: string
    default: "all"
  viewport:
    type: string
    default: "all"
  cachebuster:
    type: boolean
    default: false
  save-build:
    type: boolean
    default: true
  force-reference:
    type: boolean
    default: false

  # These params for currently used in drush ma:release
  ma-release:
    type: boolean
    default: false
  refresh-db:
    type: string
    default: ""
  skip-maint:
    type: string
    default: ""
  # target also used by ma-cf-deploy, ma-backstop
  target:
    type: string
    default: ""
  git-ref:
    type: string
    default: ""
  # Used to manually trigger workflows via the API.
  trigger_workflow:
    type: string
    default: ""
jobs:
  build:
    working_directory: ~/project/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - checkout
      - *restore_composer_cache
      - run: {name: 'Composer install', command: 'composer install --no-interaction --optimize-autoloader'}
      - *save_composer_cache
      - *yarn_install
      - enable_cacheability_headers
      - persist_to_workspace:
          root: ..
          paths: [code]

#  build_with_latest_mayflower:
#    working_directory: ~/project/code
#    docker:
#      - image: cimg/php:8.2-node
#    steps:
#      - checkout
#      - *restore_composer_cache
#      - run: {name: 'Composer install', command: 'composer install --no-interaction --optimize-autoloader'}
#      - run:
#          name: Update Mayflower to latest develop
#          command: composer -n -vvv require massgov/mayflower-artifacts:dev-develop --update-with-dependencies
#      - *save_composer_cache
#      - *yarn_install
#      - enable_cacheability_headers
#      - persist_to_workspace:
#          root: ..
#          paths: [code]

  push_acquia:
    working_directory: ~/project/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - *no_host_check
      - *no_ssh_timeout
      - checkout
      - fetch_drush_aliases
      - run: git add -f ./drush/sites/self.site.yml
      - *restore_composer_cache
      - run: { name: 'Composer install', command: 'composer install --no-dev --no-interaction --optimize-autoloader' }
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      # Prep for push to Acquia Git. Do so while we have a clean build.
      - run: ( find docroot -type d -name .git && find docroot -type f -name .gitmodules ) | xargs rm -rf
      - run: git add -A -f .
      - run: git commit -m "Add vendor code and drush alias."
      # Add a deployment identifier file and push current branch to Acquia's Git repo.
      - run: scripts/stamp-and-deploy

  # Run Danger to check for a changelog file in the PR.
  danger:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - run:
          #Fail when there is no PR. This helps avoid false positives given by Danger when no PR exists.
          command: '[ -n "$CIRCLE_PULL_REQUEST" ] && DANGER_GITHUB_API_TOKEN=$GITHUB_MASSGOV_BOT_TOKEN yarn danger ci --failOnErrors'

  # Automate the tagging process in GitHub
  tagging_github:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - *no_host_check
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      - run: php scripts/tag-github.php

  # Automate the tagging process by using the GitHub then pushing to Acquia repository.
  tagging_acquia:
    docker:
      - image: cimg/php:8.2-node
    steps:
      - *no_host_check
      - checkout
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      # Push this build to Acquia's master branch, and tag it there.
      # @todo When needed, switch to https://circleci.com/developer/orbs/orb/circleci/github-cli
      - run: scripts/tag-release-deploy

  acquia_db_backup:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: { at: /tmp }
      - fetch_drush_aliases
      - *vendor_bin_add_path
      - run:
          command: "drush ma:backup -v prod"

  validate:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp }
      - *vendor_bin_add_path
      # Validate .json and check if it is in sync with the .lock file
      - run: composer -n validate
      # Make sure changelogs are parseable by PHP (since build-changelog.php requires that).
      - run: php scripts/directory-yaml-parse.php
      # https://architecture.lullabot.com/adr/20211201-use-strict-types-in-php-code/
      # New php files must use strict types.
      # @todo Handle deleted files.
      # - run: scripts/phpcs-new-files
      # Lint javascript
      - run: yarn run eslint --debug --ignore-path '.eslintignore' 'docroot/modules/custom/**/*.js' 'docroot/themes/custom/**/*.js' 2>&1
      # Check coding standards with php code sniffer. See phpcs.xml
      - run: vendor/bin/phpcs -v -n -s
      # Lint Twig
      - run: composer twigcs -- --no-interaction

  test:
    parameters:
      instance:
        type: string
        default: massgov/mysql-sanitized:latest
      command:
        type: enum
        enum: ['phpunit', 'behat']
    executor:
      name: base
      instance: << parameters.instance >>
    parallelism: 4
    steps:
      - attach_workspace: {at: /var/www}
      - *vendor_bin_add_path
      - run: { name: 'Start Apache', command: '/usr/local/bin/apache2-foreground-enhanced', background: true }
      - run:
          name: Update host file
          command: echo '127.0.0.1 mass.local' >> /etc/hosts
      - run:
          name: Wait for mysql
          command: dockerize -wait tcp://localhost:3306 -timeout 2m
      # Run drush updatedb and cim.
      - run: drush deploy
      # Get an overview
      - run: drush status
      - run: cat /proc/cpuinfo
      - run: cat /proc/meminfo
      # We've adopted the decision at https://architecture.lullabot.com/adr/20211212-config-status-check/.
      - run:
          name: Ensure no differences between between config on disk and config in Drupal.
          # --no will error if there are differences as per https://github.com/drush-ops/drush/issues/4770
          command: drush --no config:export --diff
      # Ensure files and DTT directories are writable by www-data
      - run: mkdir -p output/behat docroot/sites/default/files docroot/sites/simpletest/browser_output
      - run: chown -R www-data:www-data docroot/sites/default/files docroot/sites/simpletest/browser_output
      # Run DTT or Behat test command
      - when:
          condition:
            and:
              - equal: [ behat, << parameters.command >> ]
          steps:
            run: behat --profile=ci --strict --format=junit --out=/tmp/test-results/behat --format=pretty --out=std
      - when:
          condition:
            and:
              - equal: [ phpunit, << parameters.command >> ]
          steps:
#            run: 'su -s /bin/bash root -c "phpunit docroot/modules/custom --testdox --log-junit /tmp/test-results/dtt/junit.xml"'
            - run:
                # https://circleci.com/docs/use-the-circleci-cli-to-split-tests/#configure-a-job-running-phpunit-testshttps://circleci.com/docs/use-the-circleci-cli-to-split-tests/#configure-a-job-running-phpunit-tests
                name: Run functional tests
                command: |
                  TESTS_TO_RUN=$(phpunit-finder --config-file /var/www/code/phpunit.xml.dist --bootstrap-file /var/www/code/vendor/weitzman/drupal-test-traits/src/bootstrap.php)
                  echo "$TESTS_TO_RUN" | circleci tests run --command="xargs -I{} -d\" \" phpunit {} --log-junit /tmp/test-results/dtt/$(basename {}).xml" --verbose --split-by=timings
      - store_test_results:
          path: /tmp/test-results
      - store_artifacts:
          # Pages saved via 'Then save the html for the page'. @see \FeatureContext::saveHtml.
          path: /var/www/code/output
      - store_artifacts:
          # DTT saves page output for all requests.
          path: /var/www/code/docroot/sites/simpletest/browser_output
      - store_artifacts:
          # Save Junit files for timing inspection.
          path: /tmp/test-results

  # Cut the release branch for weekly release
  cut_release_branch:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - *vendor_bin_add_path
      - *no_host_check
      - checkout
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      # Create a release branch from the develop branch in GitHub.
      - run:
          command: "php scripts/build-changelog.php"

  # Create the mayflower branch for testing the develop branch.
  mayflower_develop_branch:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - *vendor_bin_add_path
      - *no_host_check
      - checkout
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      # Create a release branch from the develop branch in GitHub.
      - run:
          command: "php scripts/ma-mayflower-develop.php"

  # Log a new release in New Relic
  new_relic_change_tracking:
    docker:
      - image: cimg/php:8.2-node
    parameters:
      version:
        type: string
    steps:
      # Install NR CLI
      - run: curl -Ls "https://download.newrelic.com/install/newrelic-cli/scripts/install.sh" | bash
      # https://docs.newrelic.com/docs/change-tracking/change-tracking-cli/
      # https://circleci.com/docs/variables/#built-in-environment-variables
      # The GUID is for the mass.gov prod entity. Browse all entities with `newrelic apm application search --name mass.gov`
      - run: NEW_RELIC_API_KEY=$MASS_NEWRELIC_KEY newrelic entity deployment create --accountId $MASS_NEWRELIC_APPLICATION --guid MTUyMjA0MXxBUE18QVBQTElDQVRJT058NzIwNjAyNjQz --version << parameters.version >> --commit $CIRCLE_SHA1 --deepLink $CIRCLE_BUILD_URL

      # Post-release merge from master to develop.
  master_to_develop:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: { at: /tmp }
      - *vendor_bin_add_path
      - *no_host_check
      - checkout
      # Identify the committer i.e. CircleCI deployment bot
      - git_configure_user
      - run:
          command: "scripts/master-to-develop"

  deploy:
    parameters:
      target:
        type: string
      gitRef:
        type: string
        default: $CIRCLE_BRANCH
      skip-maint:
        type: enum
        enum: ["", "--skip-maint"]
        default: ""
      refresh-db:
        type: enum
        enum: ["", "--refresh-db"]
        default: ""
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - *no_host_check
      - *no_ssh_timeout
      - *vendor_bin_add_path
      - fetch_drush_aliases
      - run:
          command: "drush ma:deploy -v -y << parameters.skip-maint >> << parameters.refresh-db >> << parameters.target >> << parameters.gitRef >>"
          no_output_timeout: 60m
      - jira/notify:
          environment: << parameters.target >>
          environment_type: development
          job_type: deployment
          token_name: CIRCLE_PERSONAL_TOKEN

  crawl:
    parameters:
      samples:
        type: integer
      target:
        type: string
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - *vendor_bin_add_path
      - *no_host_check
      - *no_ssh_timeout
      - fetch_drush_aliases
      - run: mkdir -p /tmp/results/junit
      - run:
          name: Nightcrawler
          command: nightcrawler --config=./.circleci/nightcrawler/nightcrawler.js crawl --concurrency 1 --json /tmp/results/results.json --junit /tmp/results/junit/crawler.xml --target=<< parameters.target >> --samples=<< parameters.samples >>
          no_output_timeout: 300m
      - store_test_results:
          path: /tmp/results
      - store_artifacts:
          path: /tmp/results

  browserstack_test:
    working_directory: /tmp/code/.circle/browserstack
    docker:
      - image: cimg/php:8.2-node
        environment:
          BROWSERSTACK_USERNAME: $BROWSERSTACK_USERNAME
          BROWSERSTACK_ACCESS_KEY: $BROWSERSTACK_ACCESS_KEY
          BROWSERSTACK_LOCAL: false
          BROWSERSTACK_LOCAL_IDENTIFIER: "identifier"
    steps:
      - attach_workspace: {at: /tmp}
      - *vendor_bin_add_path
      - *no_host_check
      - *no_ssh_timeout
      - run:
          name: BrowserStack Automate
          command: yarn install && npm run snapshots-test
          no_output_timeout: 300m
      - store_test_results:
          path: /tmp/results
      - store_artifacts:
          path: /tmp/results


  backstop_reference:
    parameters:
      target:
        type: string
        default: prod
      list:
        type: string
        default: all
      viewport:
        type: string
        default: all
      cachebuster:
        type: boolean
        default: false
      save-build:
        type: boolean
        default: true
    resource_class: xlarge
    docker:
      # Update this in .ddev/.disabled-services/docker-compose.backstop.yaml too.
      - image: backstopjs/backstopjs:6.3.3
    steps:
      - checkout
      - run:
          name: "Setup environment variables"
          command: |
            if [ "<< parameters.cachebuster >>" = "true" ]; then
              echo 'export CACHEBUSTER="--cachebuster"' >> "$BASH_ENV"
            fi
      - run:
          name: Capture Backstop Reference Screenshots
          working_directory: backstop
          command: |
            EXIT_CODE=0
            backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js || EXIT_CODE=$?
            # Retry
            if [ "$EXIT_CODE" != "0" ]; then
              backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js || EXIT_CODE=$?
            fi
            # Retry
            if [ "$EXIT_CODE" != "0" ]; then
              backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js
            fi
      - run:
          name: Archive Reference Screenshots
          command: |
            apt-get update
            apt-get install zip -y
            zip -r references.zip backstop/reference
      - store_artifacts:
          path: references.zip
          destination: backstop-<< parameters.target >>-<< parameters.list >>-<< parameters.viewport >>-latest
      - store_artifacts:
          path: backstop/reference
      - run:
          name: Save Build Number
          command: |
            if [ "<< parameters.save-build >>" = "true" ]; then
              curl --request POST \
                --fail \
                --url "https://circleci.com/api/v2/project/gh/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/envvar" \
                --header "Circle-Token: $CIRCLE_PERSONAL_TOKEN" \
                --header 'content-type: application/json' \
                --data "{\"name\":\"BACKSTOP_REF_<< parameters.target >>_<< parameters.list >>_<< parameters.viewport >>\",\"value\":\"$CIRCLE_BUILD_NUM\"}"
            fi

  backstop_test:
    parameters:
      reference:
        type: string
        default: prod
      target:
        type: string
        default: test
      list:
        type: string
        default: all
      viewport:
        type: string
        default: all
      tugboat:
        type: string
        default: ""
      cachebuster:
        type: boolean
        default: false
      force-reference:
        type: boolean
        default: false
    resource_class: 2xlarge+
    docker:
      # Update this in .ddev/.disabled-services/docker-compose.backstop.yaml too.
      # Update this after https://github.com/garris/BackstopJS/issues/1468
      - image: backstopjs/backstopjs:6.1.4
    steps:
      - checkout
      - run:
          name: "Setup environment variables"
          command: |
            if [ "<< parameters.cachebuster >>" = "true" ]; then
              echo 'export CACHEBUSTER="--cachebuster"' >> "$BASH_ENV"
            fi
      - when:
          condition: << parameters.force-reference >>
          steps:
            - run:
                name: Capture Backstop Reference Screenshots
                working_directory: backstop
                command: |
                  EXIT_CODE=0
                  backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js || EXIT_CODE=$?
                  # Retry
                  if [ "$EXIT_CODE" != "0" ]; then
                    backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js || EXIT_CODE=$?
                  fi
                  # Retry
                  if [ "$EXIT_CODE" != "0" ]; then
                    backstop reference --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER} --config backstop.js
                  fi
      - unless:
          condition: << parameters.force-reference >>
          steps:
            - run:
                name: Verify Artifacts
                command: |
                  wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
                  apt-get update
                  apt-get install jq -y
                  BACKSTOP_REF="BACKSTOP_REF_<< parameters.reference >>_<< parameters.list >>_<< parameters.viewport >>"
                  if [ "${!BACKSTOP_REF}" == "" ]; then
                    echo "No artifacts found for << parameters.reference >>_<< parameters.list >>_<< parameters.viewport >>"
                    exit 1
                  fi
                  STOPPED_AT=$(curl --request GET \
                    --fail \
                    --url https://circleci.com/api/v2/project/gh/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/job/${!BACKSTOP_REF} \
                    --header "Circle-Token: $CIRCLE_PERSONAL_TOKEN" | jq -r '.stopped_at')
                  LAST_SUCCESS=$(date -d "$STOPPED_AT" +%s)
                  STALE_TIME=$(date -d "-168 hours" +%s)
                  if [ $LAST_SUCCESS -lte $STALE_TIME ]; then
                    echo "Reference images are stale, please re-run the nightly_backstop_snapshot workflow or run `drush ma:ci:backstop-snapshot --target=<< parameters.reference >> --list=<< parameters.list >> --viewport=<< parameters.viewport >>` locally"
                    exit 1
                  fi
            - run:
                name: Restore Artifacts
                command: |
                  BACKSTOP_REF="BACKSTOP_REF_<< parameters.reference >>_<< parameters.list >>_<< parameters.viewport >>"
                  URL=$(curl --request GET \
                    --fail \
                    --url https://circleci.com/api/v2/project/gh/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/${!BACKSTOP_REF}/artifacts \
                    --header "Circle-Token: $CIRCLE_PERSONAL_TOKEN" | jq -r '.items | .[] | select(.path=="backstop-<< parameters.reference >>-<< parameters.list >>-<< parameters.viewport >>-latest") | .url')
                  curl --fail --location --url $URL --output backstop_ref.zip
                  unzip backstop_ref.zip
                  rm backstop_ref.zip
      - when:
          condition: << parameters.tugboat >>
          steps:
            - run:
                name: Backstop test (Tugboat target)
                working_directory: backstop
                command: backstop --config=backstop.js test --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> --tugboat=<< parameters.tugboat >> ${CACHEBUSTER}
      - unless:
          condition: << parameters.tugboat >>
          steps:
            - run:
                name: Backstop test (non Tugboat target)
                working_directory: backstop
                command: backstop --config=backstop.js test --target=<< parameters.target >> --list=<< parameters.list >> --viewport=<< parameters.viewport >> ${CACHEBUSTER}
                no_output_timeout: 300m
      - store_test_results:
          path: backstop/report
      - store_artifacts:
          path: backstop

  # If you make changes to this job, consider pushing to a tag that's not 'latest'
  # at Docker Hub. That way, your in-progress work does not interfere with build
  # happening in the build_test workflow.
  populate:
    description: "Sanitize a mysql database and push to Docker Hub"
    parameters:
      sanitizeOption:
        type: string
        default: --sanitize
      instance:
        type: string
      resource_class:
        type: string
        default: large
    working_directory: /home/circleci/code/.circleci/mysql-rebuild
    resource_class: << parameters.resource_class >>
    machine:
      image: ubuntu-2004:202101-01
    steps:
      - attach_workspace: {at: /home/circleci}
      - fetch_drush_aliases:
          destination: /home/circleci/code/drush/sites/self.site.yml
      - run: docker-compose up -d
      - run: docker cp /home/circleci/code/. "$(docker-compose ps -q drupal)":/var/www/html
      # @todo Actually perform health check.
      - run:
          name: Wait for mysql
          command: sleep 5
      - run: docker-compose exec drupal sudo apk add --no-cache --upgrade grep
      - run:
          command: docker-compose exec drupal scripts/ma-refresh-local --db-prep-only
          no_output_timeout: 60m
      - run: docker login -u $DOCKER_USER -p $DOCKER_API_KEY
      - run:
          command: docker-compose exec drupal scripts/ma-refresh-local << parameters.sanitizeOption >>
          no_output_timeout: 30m
      - run: docker-compose exec drupal drush cr
      - run: docker-compose stop --timeout 60 mysql
      - run: docker commit $(docker-compose ps -q mysql) << parameters.instance >>
      - run: docker push << parameters.instance >>

  pending_security:
    working_directory: /tmp/code
    docker:
      - image: cimg/php:8.2-node
    steps:
      - attach_workspace: {at: /tmp}
      - run: "composer audit --no-interaction --no-dev"

workflows:
  build_test:
    when:
      and:
        - << pipeline.parameters.webhook >>
        - not: << pipeline.parameters.trigger_workflow >>
    jobs:
      - build:
          filters:
            branches:
              ignore:
                - /^release\/.*$/
                - /^hotfix\/.*$/
                - master
                - /^mayflower-dev-.*/
      - validate:
          requires: [build]
          filters:
            branches:
              <<: *branch_ignore
      - danger:
          requires: [build]
          filters:
            branches:
              ignore:
                - develop
      - push_acquia:
          filters:
            branches:
              <<: *branch_ignore
      - test:
          name: test-phpunit
          command: phpunit
          requires: [build]
          filters:
            branches:
              <<: *branch_ignore
      - test:
          name: test-behat
          command: behat
          requires: [build]
          filters:
            branches:
              <<: *branch_ignore
      - browserstack_test:
          requires: [build]
          filters:
            branches:
              <<: *branch_ignore

  # This is to automate the creation of the release branch.
  # The cron time needs to be updated every Fall/Spring for daylight saving time.
  release_branch:
    when:
      and:
        - equal: [ release_branch, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - cut_release_branch:
          requires: [build]

  # This is to automate the release branch only.
  release:
    jobs:
      - build:
          filters:
            branches:
              only: /^release\/.*$/
      - push_acquia:
          filters:
            branches:
              only: /^release\/.*$/
      - test:
          name: test-phpunit
          command: phpunit
          requires: [build]
          filters:
            branches:
              only: /^release\/.*$/
      - test:
          name: test-behat
          command: behat
          requires: [build]
          filters:
            branches:
              only: /^release\/.*$/
      - deploy:
          name: deploy-test-refresh-db
          requires:
            - build
            - push_acquia
          target: test
          refresh-db: "--refresh-db"
          filters:
            branches:
              only: /^release\/.*$/
      - crawl:
          name: crawl-test-350
          requires: [deploy-test-refresh-db]
          target: test
          samples: 350
          filters:
            branches:
              only: /^release\/.*$/
      - backstop_test:
          name: backstop-test
          requires: [deploy-test-refresh-db]
          target: test
          reference: prod
          filters:
            branches:
              only: /^release\/.*$/
      - hold - QA approval:
          name: hold-qa-approval
          requires: [deploy-test-refresh-db]
          type: approval
          filters:
            branches:
              only: /^release\/.*$/

  # This is to automate the hotfix branch only.
  hotfix:
    when: << pipeline.parameters.webhook >>
    jobs:
      - build:
          filters:
            branches:
              only: /^hotfix\/.*$/
      - push_acquia:
          filters:
            branches:
              only: /^hotfix\/.*$/
      - test:
          name: test-phpunit
          command: phpunit
          requires: [build]
          filters:
           branches:
             only: /^hotfix\/.*$/
      - test:
          name: test-behat
          command: behat
          requires: [build]
          filters:
            branches:
              only: /^hotfix\/.*$/
      - hold - Release manager only:
            type: approval
            requires:
              - build
              - push_acquia
            filters:
              branches:
                only: /^hotfix\/.*$/
      - deploy:
          name: deploy-test-no-refresh-db
          requires:
            - hold - Release manager only
          target: test
          filters:
            branches:
              only: /^hotfix\/.*$/
      - crawl:
            name: crawl-test-50
            requires: [deploy-test-no-refresh-db]
            target: test
            samples: 50
            filters:
              branches:
                only: /^hotfix\/.*$/
      - backstop_test:
            name: backstop-test
            requires: [deploy-test-no-refresh-db]
            target: test
            reference: prod
            filters:
              branches:
                only: /^hotfix\/.*$/
      - hold - QA approval:
          name: hold-qa-approval
          requires: [push_acquia]
          type: approval
          filters:
            branches:
              only: /^hotfix\/.*$/

  # This is to automate the mayflower branch only.
  mayflower:
    when: << pipeline.parameters.webhook >>
    jobs:
      - build:
          filters:
            branches:
              only: /^mayflower\/.*$/
      - validate:
          requires: [build]
          filters:
            branches:
              only: /^mayflower\/.*$/
      - danger:
          requires: [build]
          filters:
            branches:
              only: /^mayflower\/.*$/
      - push_acquia:
          filters:
            branches:
              only: /^mayflower\/.*$/
      - test:
          name: test-phpunit
          command: phpunit
          requires: [build]
          filters:
            branches:
              only: /^mayflower\/.*$/
      - test:
          name: test-behat
          command: behat
          requires: [build]
          filters:
            branches:
              only: /^mayflower\/.*$/
      - hold - Release manager only:
          type: approval
          requires:
            - build
            - push_acquia
          filters:
            branches:
              only: /^mayflower\/.*$/
      - deploy:
          name: deploy-test-refresh-db
          requires:
            - hold - Release manager only
          target: test
          refresh-db: "--refresh-db"
          filters:
            branches:
              only: /^mayflower\/.*$/
      - crawl:
          name: crawl-test-250
          requires: [deploy-test-refresh-db]
          target: test
          samples: 250
          filters:
            branches:
              only: /^mayflower\/.*$/
      - backstop_test:
          name: backstop-test
          requires: [deploy-test-refresh-db]
          target: test
          reference: prod
          filters:
            branches:
              only: /^mayflower\/.*$/

  # This is to tag the release in the GitHub repository
  build_github_tag:
    when: << pipeline.parameters.webhook >>
    jobs:
      - build:
          filters:
            branches:
              only: master
      - test:
          name: test-phpunit
          command: phpunit
          requires: [build]
          filters:
            branches:
              only: master
      - test:
          name: test-behat
          command: behat
          requires: [build]
          filters:
            branches:
              only: master
      - hold - Release manager only:
          type: approval
          requires:
            - build
          filters:
            branches:
              only: master
      - tagging_github:
          requires:
              - hold - Release manager only
          filters:
            branches:
              only: master

  # This deploys the newly created tag to stage environment and production environment with hold/approval for each job.
  build_tag:
    when: << pipeline.parameters.webhook >>
    jobs:
      - build:
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - push_acquia:
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - tagging_acquia:
          requires:
            - push_acquia
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - hold_for_stage Release manager only:
          type: approval
          requires:
            - build
            - tagging_acquia
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - deploy:
          name: deploy-tag-stage-acquia
          requires:
            - build
            - tagging_acquia
            - hold_for_stage Release manager only
          gitRef: tags/$CIRCLE_TAG
          target: test
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - hold_for_prod_maint Release manager only:
          type: approval
          requires:
            - build
            - tagging_acquia
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - deploy:
          name: deploy-tag-prod-acquia-maint
          requires:
            - build
            - tagging_acquia
            - hold_for_prod_maint Release manager only
          target: prod
          gitRef: tags/$CIRCLE_TAG
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - hold_for_prod_no_maint Release manager only:
          type: approval
          requires:
            - build
            - tagging_acquia
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - deploy:
          name: deploy-tag-prod-acquia-no-maint
          requires:
            - build
            - tagging_acquia
            - hold_for_prod_no_maint Release manager only
          target: prod
          gitRef: tags/$CIRCLE_TAG
          skip-maint: --skip-maint
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - backstop_test:
          name: backstop-prod-maint
          requires: [deploy-tag-prod-acquia-maint]
          target: prod
          list: post-release
          viewport: desktop
          reference: test
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - new_relic_change_tracking:
          name: new-relic-change-tracking-prod-maint
          requires: [deploy-tag-prod-acquia-maint]
          version: $CIRCLE_TAG
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - new_relic_change_tracking:
          name: new-relic-change-tracking-prod-no-maint
          requires: [ deploy-tag-prod-acquia-no-maint ]
          version: $CIRCLE_TAG
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - master_to_develop:
          name: master-to-develop-prod-no-maint
          requires: [ deploy-tag-prod-acquia-no-maint ]
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - master_to_develop:
          name: master-to-develop-prod-maint
          requires: [ deploy-tag-prod-acquia-maint ]
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - master_to_develop:
          name: master-to-develop-prod-no-maint
          requires: [ deploy-tag-prod-acquia-no-maint ]
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

  # Daily run of test suite using super sanitized DB
  build_test_super:
    when:
      and:
        - equal: [ build_test_super, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - test:
          name: test-phpunit-super
          command: phpunit
          instance: massgov/mysql-sanitized:super
          requires: [build]
      - test:
          name: test-super-behat
          command: behat
          instance: massgov/mysql-sanitized:super
          requires: [build]

  # Daily rebuild of our sanitized and super-sanitized mysql data images.
  # The cron time needs to be updated every Fall/Spring for daylight saving time.
  mysql_rebuild:
    when:
      and:
        - equal: [ mysql_rebuild, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - populate:
          name: massgov.populate --sanitize
          requires: [build]
          sanitizeOption: --sanitize
          instance: massgov/mysql-sanitized:latest
      - populate:
          name: massgov.populate --super-sanitize
          requires: [build]
          sanitizeOption: --super-sanitize
          instance: massgov/mysql-sanitized:super
      - populate:
          name: massgov.populate.arm --sanitize
          requires: [ build ]
          sanitizeOption: --sanitize
          instance: massgov/mysql-sanitized:latest.arm
          resource_class: arm.large
      - populate:
          name: massgov.populate.arm --super-sanitize
          requires: [ build ]
          sanitizeOption: --super-sanitize
          instance: massgov/mysql-sanitized:super.arm
          resource_class: arm.large

  # Usually triggered by drush ma:release.
  deploy_ad_hoc:
    when: << pipeline.parameters.ma-release >>
    jobs:
      - build
      - deploy:
          requires: [build]
          target: << pipeline.parameters.target >>
          gitRef: << pipeline.parameters.git-ref >>
          skip-maint: << pipeline.parameters.skip-maint >>
          refresh-db: << pipeline.parameters.refresh-db >>

  # Nightly On Demand Prod DB Backup
  nightly_prod_db_backup:
    when:
      and:
        - equal: [ nightly_prod_db_backup, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - acquia_db_backup:
          requires: [ build ]

  # Nightly Backstop image references.
  nightly_backstop_snapshot:
    when:
      and:
        - equal: [ nightly_backstop_snapshot, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - backstop_reference:
          target: prod

  # See https://support.circleci.com/hc/en-us/articles/12419710425499-How-to-Manually-Trigger-a-Scheduled-Pipeline
  backstop_snapshot:
    when:
      and:
        - equal: [ api, << pipeline.trigger_source >> ]
        - equal: [ backstop_snapshot, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - backstop_reference:
          target: << pipeline.parameters.target >>
          list: << pipeline.parameters.list >>
          viewport: << pipeline.parameters.viewport >>
          cachebuster: << pipeline.parameters.cachebuster >>

  backstop_compare:
    when:
      and:
        - equal: [ api, << pipeline.trigger_source >> ]
        - equal: [ backstop_compare, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - backstop_test:
          target: << pipeline.parameters.target >>
          list: << pipeline.parameters.list >>
          viewport: << pipeline.parameters.viewport >>
          tugboat: << pipeline.parameters.tugboat >>
          cachebuster: << pipeline.parameters.cachebuster >>

# Nightly deploy develop branch (with the latest Mayflower develop branch) to the CD environment, runs at 11:00PM EST.
# Add the backstop one in here
  deploy_cd:
    when:
      and:
        - equal: [ deploy_cd, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - deploy:
          name: deploy-cd-refresh-db
          requires: [ build ]
          target: cd
          refresh-db: "--refresh-db"
      - backstop_test:
          requires: [ deploy-cd-refresh-db ]
          reference: prod
          target: cd
      - crawl:
          name: crawl-deploy-450
          requires: [ deploy-cd-refresh-db ]
          target: cd
          samples: 450

  # @todo remove. for PR testing via manual pipeline trigger.
  new_relic_testing:
    when:
      and:
        - equal: [ new_relic_testing, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - new_relic_change_tracking:
          version: $CIRCLE_SHA1

  # Nightly pm:security and pm:security-php.
  nightly_pending_security:
    when:
      and:
        - equal: [ nightly_pending_security, << pipeline.parameters.trigger_workflow >> ]
    jobs:
      - build
      - pending_security:
          requires: [build]
